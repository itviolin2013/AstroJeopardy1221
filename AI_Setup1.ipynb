{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f4880536-ff3f-423d-8d7e-d91a3be202c9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error: did not find key. Check that .env exists in the same folder/directory as your class notebooks\n",
            "Successfully found .gitignore in the current directory\n",
            "Confirmed that .gitignore has the .env exclusion\n"
          ]
        }
      ],
      "source": [
        "# things that i am writing are here and popping up hopefully\n",
        "# We will use this to suppress some warnings that are not important\n",
        "import warnings\n",
        "\n",
        "# Suppress specific Pydantic warnings that clutter the output\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"pydantic\")\n",
        "\n",
        "# We will use dotenv to read the .env file\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "# This import will return an error if LiteLLM is not installed \n",
        "import litellm\n",
        "import os\n",
        "\n",
        "# Use this to measure response time\n",
        "import time\n",
        "\n",
        "# URL of Ohio State's LiteLLM proxy server\n",
        "custom_api_base = \"https://litellmproxy.osu-ai.org\" \n",
        "\n",
        "# Our API key for Astronomy 1221 (keep this private to our class)\n",
        "astro1221_key = os.getenv(\"ASTRO1221_API_KEY\")\n",
        "if astro1221_key:\n",
        "    print(\"Successfully loaded Astronomy 1221 key\")\n",
        "else:\n",
        "    print(\"Error: did not find key. Check that .env exists in the same folder/directory as your class notebooks\")\n",
        "\n",
        "# Check that .gitignore exists in this directory\n",
        "if os.path.isfile('.gitignore'):\n",
        "    print(\"Successfully found .gitignore in the current directory\")\n",
        "else:\n",
        "    print(\"Error: Did not find .gitignore. Please download .gitignore from carmen and put in the same folder/directory as your class notebooks.\")\n",
        "\n",
        "with open('.gitignore', 'r') as f:\n",
        "    content = f.read()\n",
        "    if '.env' in content:\n",
        "        print(\"Confirmed that .gitignore has the .env exclusion\")\n",
        "    else: \n",
        "        print(\"Error: Did not find .env in .gitignore. Please download .gitignore from carmen and put with your class notebooks.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "38a2eb64",
      "metadata": {},
      "outputs": [],
      "source": [
        "def prompt_llm(messages, model=\"openai/GPT-4.1-mini\", temperature=0.2, max_tokens=1000):\n",
        "    \"\"\"\n",
        "    Send a prompt or conversation to an LLM using LiteLLM and return the response.\n",
        "\n",
        "    Parameters:\n",
        "        messages: Either a string (single user prompt) or a list of message dicts with\n",
        "                  \"role\" and \"content\". If a string, formatted as [{\"role\": \"user\", \"content\": messages}].\n",
        "        model (str, optional): The name of the model to use. Defaults to \"openai/GPT-4.1-mini\".\n",
        "        temperature (float, optional): Value between 0 and 2; higher values make output more random. Defaults to 0.2.\n",
        "        max_tokens (int, optional): Maximum number of tokens to generate in the completion. Must be a positive integer. Defaults to 1000.\n",
        "\n",
        "    Prints the answer returned by the model.\n",
        "    \n",
        "    Returns:\n",
        "        response: The full response object from LiteLLM.\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If `temperature` is not in [0, 2] or `max_tokens` is not a positive integer.\n",
        "    \"\"\"\n",
        "    # If messages is a string, format it as a single user message\n",
        "    if isinstance(messages, str):\n",
        "        messages = [{\"role\": \"user\", \"content\": messages}]\n",
        "    # Validate temperature\n",
        "    if not (isinstance(temperature, (int, float)) and 0 <= temperature <= 2):\n",
        "        raise ValueError(\"temperature must be a float between 0 and 2 (inclusive).\")\n",
        "    # Validate max_tokens\n",
        "    if not (isinstance(max_tokens, int) and max_tokens > 0):\n",
        "        raise ValueError(\"max_tokens must be a positive integer.\")\n",
        "\n",
        "    try: \n",
        "        print(\"Contacting LLM via University Server...\")\n",
        "\n",
        "        response = litellm.completion(\n",
        "            model=model,\n",
        "            messages=messages,\n",
        "            api_base=custom_api_base,\n",
        "            api_key=astro1221_key,\n",
        "            temperature=temperature,\n",
        "            max_tokens=max_tokens\n",
        "        )\n",
        "\n",
        "        answer = response['choices'][0]['message']['content']\n",
        "        print(f\"\\nSUCCESS! Here is the answer from {model}:\\n\")\n",
        "        print(answer)\n",
        "        print(\"\\n\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nERROR: Could not connect. Details:\\n{e}\")    \n",
        "        response = None\n",
        "\n",
        "    return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "34660474",
      "metadata": {},
      "outputs": [],
      "source": [
        "def show_response_metadata(response):\n",
        "    '''\n",
        "    Convert the response to a dictionary\n",
        "    Print information about token usage and costs\n",
        "    '''\n",
        "    \n",
        "    # Here are the top level keys\n",
        "    response_dict = response.model_dump()\n",
        "    # print(f\"Top-level keys: {response_dict.keys()}\\n\")\n",
        "    \n",
        "    # Here are more details: \n",
        "    # 1. Get the exact model version used by the server\n",
        "    used_model = response.model\n",
        "    \n",
        "    # 2. Extract token counts from the 'usage' attribute\n",
        "    input_tokens = response.usage.prompt_tokens\n",
        "    output_tokens = response.usage.completion_tokens\n",
        "    total_tokens = response.usage.total_tokens\n",
        "    \n",
        "    # 3. Calculate the cost (LiteLLM does the math based on current rates)\n",
        "    cost = litellm.completion_cost(completion_response=response)\n",
        "    \n",
        "    print(f\"--- Query Metadata ---\")\n",
        "    print(f\"Model:        {used_model}\")\n",
        "    print(f\"Input Tokens: {input_tokens}\")\n",
        "    print(f\"Output Tokens:{output_tokens}\")\n",
        "    print(f\"Total Tokens: {total_tokens}\")\n",
        "    print(f\"Estimated Cost: ${cost:.6f}\") # Showing 6 decimal places for small queries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "fb46962a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "astro_jeopardy_answers.csv exists in the current directory.\n",
            "Data array created successfully.\n",
            "The array's shape is (6, 6).\n",
            "[['Exoplanets' 'Galaxies' 'Constellations' 'Planets' 'Moons'\n",
            "  'Astronomers/Physicists/Astronauts']\n",
            " ['HD189733b' 'the Milky Way' 'Ursa Major' 'Neptune' 'Titan'\n",
            "  'Robert Henry Lawerence Jr.']\n",
            " ['Wasp 12-b' 'M31' 'Orion' 'Saturn' 'Europa' 'Kathrine Johnson']\n",
            " ['Tres 2b' 'M32' 'Cassiopeia' 'Venus' 'Enceladus' 'Sally Ride']\n",
            " ['GJ 1132b' 'M33' 'Pegasus' 'Uranus' 'Triton' 'Sunita Williams']\n",
            " ['51 Pegasi b' 'M64' 'Sagittarius' 'Earth' 'Phobos' 'Benjamin Bennecker']]\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# check path location to make sure directory is correct\n",
        "current_dir = os.getcwd()\n",
        "\n",
        "# make sure the file is in our directory\n",
        "if os.path.exists(\"astro_jeopardy_answers.csv\"):\n",
        "    print(\"astro_jeopardy_answers.csv exists in the current directory.\")\n",
        "else:\n",
        "    print(\"astro_jeopardy_answers.csv does not exist in the current directory.\")\n",
        "\n",
        "# read the file\n",
        "with open(\"astro_jeopardy_answers.csv\", \"r\") as file:\n",
        "    reader = csv.reader(file)\n",
        "    try:\n",
        "        answer = np.genfromtxt(\"astro_jeopardy_answers.csv\", delimiter=\",\", dtype=str)\n",
        "        print(\"Data array created successfully.\")\n",
        "        print(f\"The array's shape is {answer.shape}.\")\n",
        "        print(answer)\n",
        "    except Exception as e:\n",
        "        print(f\"Error creating data array: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "d4f6980b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "astro_jeopardy_facts.csv exists in the current directory.\n",
            "Data array created successfully.\n",
            "The array's shape is (5, 6).\n",
            "[['HD189733b is a Hot Jupiter exoplanet that is known for its deadly conditions such as: raining molten glass sideways and containing a disgusting smell of rotten egg. This planet also contains an abundant amount of hydrogen sulfide and was discovered through radial velocity.'\n",
            "  'The Milky Way is the galaxy we live in! The Milky Way spans across more than 100,000 light-years. It takes our solar system around 250 million years to orbit our galaxy once!'\n",
            "  'Ursa Major is also known as the Great Bear and the third largest constellation. In Greek mythology, this bear is Callisto, a nymph of Artemis that Zeus is madly in love with.'\n",
            "  'Neptune was first observed in 1612 by Galileo and was later the first planet in our solar system to be located by math in 1846. A typical day on Neptune is around 16 hours, while a typical year is around 60,190 Earth days. Due to the long years of Neptune, each of Neptunes seasons lasts over 40 years!'\n",
            "  'Titan is Saturn�s largest moon, and the second largest moon in our solar system! It is the only moon in our solar system with a dense atmosphere. Titan is the only other place in our solar system known rain- like cycle!'\n",
            "  'Robert Henry Lawerence Jr. was an air force officer, and in 1967 became the first black astronaut. While he was sadly killed before he ever got to go to space, he created a legacy that paved the way for other black people to become astronauts. He even earned his PHD in Physical Chemistry from Ohio State University!']\n",
            " ['Wasp 12-b is an exoplanet fated to eternal damnation. This planet is so close to its host star that it is being gravitationally sucked into it. Eventually in about a few billion years, it will no longer exist, and is egg shaped because of these interactions with its host star. It is a gas giant and discovered by transit.'\n",
            "  'The Andromeda Galaxy (also known as Messier 31) is a spiral galaxy. It is the closet galaxy to us! The first known report of the galaxy was found in the year 964 in a book by Persian astronomer Abd al-rahman al Sufi.'\n",
            "  'Orion was named after a hunter in ancient Greek mythology who was Poseidon�s son. It depicts Orian�s belt, sword, head, club, and shield, and contains the star Betelgeuse.'\n",
            "  \"Saturn�s rings are believed to be comprised of bits of asteroids, comets, and debris from shattered moons. These rings extend upwards of 175,000 miles  from Saturn's surface. Saturn is mainly composed of Hydrogen and Helium, much like Jupiter�s!\"\n",
            "  \"Europa is one of Jupiter's largest moons! There is sufficient evidence for oceans to be beneath the icy surface of the moon! Cracks in the surface of the moon are likely a result of flowing liquid on its surface. Europa is in resonance with with Io and Ganymede.\"\n",
            "  'Kathrine Johnson was a NASA mathematician who calculated orbital mechanics that was essential for the success of crewed spaceflight. She is also remembered as one of the first black women to work for NASA. Katherine was also considered to be a �human computer� and is featured in the well-known movie Hidden Figures.']\n",
            " ['Tres 2b is a gas giant that is the darkest known planet orbiting a star. It was found through transit and described to be less reflective than coal. The planet is super-hot and is believed to be so dark due to titanium oxide.'\n",
            "  'In 1749, Messier 32 was discovered by French astronomer Guillaume Le Gentil. It is an elliptical galaxy 2.5 million lightyears away from our own and is one of two satellite galaxies that orbit the Andromeda Galaxy.'\n",
            "  'The constellation of Cassiopeia is easily recognizable due to its �W� shape. It�s named after the queen Cassiopeia, who in Greek mythology was placed in the sky as a punishment by Poseidon for boasting of her daughter�s beauty.'\n",
            "  'Venus is one of the two planets in our solar system that does not have any moons! Temperatures on the surface become as warm as 900 degrees! (Fahrenheit)'\n",
            "  'Enceladus is a small icy moon orbiting Saturn! It has most of the chemicals needed to sustain life. This moon has the most reflective surface in the solar system. It is thought to be one of the few bodies with an ocean beneath its surface.'\n",
            "  'Sally Ride was the first and currently the only openly gay astronaut. She was also the first American woman to go to space and was aboard the Challenger. In other missions she maneuvered a robotic arm. In 2013, after her death she was awarded the Presidential Medal of Freedom.']\n",
            " ['GJ 1132b is a super earth exoplanet found through transit. This exoplanet might have begun as a mini-Neptune before it met classifications to become a super earth. It previously had an atmosphere that became lost but regained one back due to volcanic activity.'\n",
            "  'The Triangular Galaxy (also known as Messier 33)  is a part of around 30 galaxies that surround our Milky Way known as the Local Group. Messier 33 is the third largest in the group. Though images from the Hubble, it is seen that this galaxy has rapid star birth around 10x the average in the Andromeda galaxy.'\n",
            "  'The constellation of Pegasus takes the shape of a winged horse. In Greek mythology, Pegasus was born when Poseidon cut off Medusa�s head and later became Bellerophon�s horse to defeat the Chimera.'\n",
            "  'Uranus has 28 moons as well as 13 rings! Unlike any other planet orbiting our star, Uranus rotates on a nearly 90 degree angle, appearing to spins on its side. This planet is one of the two ice giants in our solar system.'\n",
            "  'Triton is Neptunes largest moon! Triton is the only large moon in our solar system that has a retrograde orbit! Triton is locked in synchronous with Saturn, like the moon is with Earth. It is one of the few geologically active moons in the solar system!'\n",
            "  'Sunita Willaims held the record for time for total days and time outside the space craft for women in space until 2015. She is well known for being stranded in space, and brought her total number of days in space to 608, the second highest amount of days.']\n",
            " ['51 Pegasi b is a hot Jupiter and is known as being the first exoplanet to be discovered. This planet can reach temperatures up to 1830 degrees F. There was thought to potentially be water in its atmosphere by a discovery in 2017.'\n",
            "  'Messier 64 is also known as the Black Eye Galaxy. Dark dust and gas partially obscure its bright core, and oddly the gas on the outer regions rotate in the opposite direction from the gas in the inner region. It is believed that this phenomenon was caused by a collision between M64 and a satellite galaxy over a billion years ago!'\n",
            "  'The center of the Milky Way lies in the westernmost part of Sagittarius. In Greek mythology, Sagittarius is depicted as a centaur, and in astrology, the sign Sagittarius is from November 22 to December 21.'\n",
            "  'Earth is our home, and the only known planet to sustain intelligent life! Earth is the only planet in which it�s name is not rooted in Greek or Roman mythology. Our names has Germanic roots, translating to � the ground�.'\n",
            "  'Phobos is the larger of the two Martian moons. It was discovered in 1877. Phobos orbits Mars three times in a singular day! Phobos has no atmosphere.'\n",
            "  'Benjamin Bennecker had great discoveries that correctly predicted the position of the sun, moon, and the planets. He built a wooden pocket watch that has read precise time for over 40 years. In 1788 he was even able to accurately predict a solar eclipse.']]\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# check path location to make sure directory is correct\n",
        "current_dir = os.getcwd()\n",
        "\n",
        "# make sure the file is in our directory\n",
        "if os.path.exists(\"astro_jeopardy_facts.csv\"):\n",
        "    print(\"astro_jeopardy_facts.csv exists in the current directory.\")\n",
        "else:\n",
        "    print(\"astro_jeopardy_facts.csv does not exist in the current directory.\")\n",
        "\n",
        "# read the file\n",
        "# Note: np.genfromtxt expects the SAME number of columns on every row.\n",
        "# The header has no @ (1 column), but fact lines have @ at start (2 columns) -> \"got 2 columns instead of 1\"\n",
        "# Fix: read line-by-line and extract the fact text (everything after @)\n",
        "with open(\"astro_jeopardy_facts.csv\", \"r\") as file:\n",
        "    facts_list = []\n",
        "    next(file)  # skip header row\n",
        "    for line in file:\n",
        "        line = line.strip()\n",
        "        if line.startswith(\"@\"):\n",
        "            facts_list.append(line[1:].strip())  # remove @ and get fact text\n",
        "        # skip merge conflict lines and other non-fact lines\n",
        "    facts = np.array(facts_list)\n",
        "    desired_shape = (5, 6)\n",
        "    facts2 = np.array(facts_list).reshape(desired_shape)\n",
        "    print(\"Data array created successfully.\")\n",
        "    print(f\"The array's shape is {facts2.shape}.\")\n",
        "    print(facts2)  # Show first 3 facts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "e9a38b6c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Contacting LLM via University Server...\n",
            "\n",
            "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
            "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
            "\n",
            "\n",
            "ERROR: Could not connect. Details:\n",
            "litellm.AuthenticationError: AuthenticationError: OpenAIException - The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'model_dump'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m      9\u001b[39m messages = [{\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33msystem\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: chat_assignment}, \n\u001b[32m     10\u001b[39m {\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: prompt}]\n\u001b[32m     12\u001b[39m response = prompt_llm(messages)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mshow_response_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mshow_response_metadata\u001b[39m\u001b[34m(response)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m'''\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03mConvert the response to a dictionary\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03mPrint information about token usage and costs\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[33;03m'''\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Here are the top level keys\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m response_dict = \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_dump\u001b[49m()\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# print(f\"Top-level keys: {response_dict.keys()}\\n\")\u001b[39;00m\n\u001b[32m     10\u001b[39m \n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Here are more details: \u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# 1. Get the exact model version used by the server\u001b[39;00m\n\u001b[32m     13\u001b[39m used_model = response.model\n",
            "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'model_dump'"
          ]
        }
      ],
      "source": [
        "chat_assignment = f\"\"\"You are Alex Trebek hosting a game of Astronomy-themed Jeopardy. Generate one Jeopardy-style\n",
        "     clue using the given facts, with the answer being {answer[1,2]} in the following category: {answer[0,2]}. \n",
        "     Do not mention the answer in the prompt, and only include the clue in your response.\"\"\"\n",
        "prompt = \"Ursa Major is also known as the Great Bear and the third largest constellation. In Greek mythology, this bear is Callisto, a nymph of Artemis that Zeus is madly in love with.\"\n",
        "# Next steps: make a for loop to run through each individual clue and answer in facts array. Then append each one to a \n",
        "# list and then make a numpy array. Read astro_jeopardy_facts.csv and also make it into a numpy array using the same \n",
        "# method as above. Replace the prompt variable with the corresponding row and column from the numpy array (the one with facts)\n",
        "\n",
        "messages = [{\"role\": \"system\", \"content\": chat_assignment}, \n",
        "{\"role\": \"user\", \"content\": prompt}]\n",
        "\n",
        "response = prompt_llm(messages)\n",
        "print(show_response_metadata(response))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
